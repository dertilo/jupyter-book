{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Manager in Plato trained with Reinforcement Learning\n",
    "\n",
    "✨**experimental**✨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching origin\n",
      "Your branch is behind 'origin/actorcritic' by 1 commit, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "Updating 70edd6b..409a14f\n",
      "Fast-forward\n",
      " .../DialoguePolicy/ReinforcementLearning/pytorch_reinforce_policy.py    | 2 +-\n",
      " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://gitlab.tubit.tu-berlin.de/OKS/plato\n",
      "   70edd6b..409a14f  actorcritic -> origin/actorcritic\n",
      "Already on 'actorcritic'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "REPOSRC=https://gitlab.tubit.tu-berlin.de/OKS/plato.git\n",
    "REPODIR=plato\n",
    "REROGIT=$REPODIR/.git\n",
    "\n",
    "[ -d $REROGIT ] || git clone $REPOSRC $REPODIR\n",
    "(cd $REPODIR; git remote update && git checkout actorcritic && git merge origin/actorcritic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (4.45.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.0.3)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from pandas>=0.23.4->-r requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from pandas>=0.23.4->-r requirements.txt (line 2)) (1.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from pandas>=0.23.4->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.23.4->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: torch==1.2.0 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: torchtext in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (0.5.0)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from torch==1.2.0) (1.18.2)\n",
      "Requirement already satisfied: sentencepiece in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from torchtext) (0.1.85)\n",
      "Requirement already satisfied: six in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from torchtext) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from torchtext) (4.45.0)\n",
      "Requirement already satisfied: requests in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from torchtext) (2.23.0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from requests->torchtext) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from requests->torchtext) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages (from requests->torchtext) (2020.4.5.1)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting scipy>=0.17.0\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=958134df2edcd039a724b5e78246f988f534d521af78802601d325043076b4c0\n",
      "  Stored in directory: /home/jupyter-tilo/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scipy, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source activate plato\n",
    "cd plato\n",
    "pip install -r requirements.txt\n",
    "pip install torch==1.2.0 torchtext sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-tilo/.conda/envs/plato/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "\r",
      "0it [00:00, ?it/s[{'dialogue': 0, 'success-rate': 0.0, 'loss': 0.0}]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! SlotFillingDialogueState not provided with slots, using default CamRest slots.\n",
      "PolicyAgent(\n",
      "  (encoder): StateEncoder(\n",
      "    (embedding): Embedding(62, 32, padding_idx=1)\n",
      "    (convnet): Sequential(\n",
      "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (1): ELU(alpha=1.0)\n",
      "      (2): Conv1d(64, 64, kernel_size=(3,), stride=(2,))\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): Conv1d(64, 64, kernel_size=(3,), stride=(2,))\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "      (7): ELU(alpha=1.0)\n",
      "    )\n",
      "    (pooling): AdaptiveMaxPool1d(output_size=1)\n",
      "  )\n",
      "  (actor): Actor(\n",
      "    (intent_head): Linear(in_features=64, out_features=15, bias=True)\n",
      "    (slots_head): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:18,  5.46it/s[{'dialogue': 99, 'success-rate': 0.84, 'loss': 17.782, 'eps': 1.0}]]\n",
      "0it [00:00, ?it/s[{'dialogue': 0, 'success-rate': 0.0, 'loss': 0.0}]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dialogue Success Rate: 100.0\n",
      "Average Cumulative Reward: 19.5095\n",
      "Average Turns: 10.81\n",
      "WARNING! SlotFillingDialogueState not provided with slots, using default CamRest slots.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:14,  6.84it/s[{'dialogue': 99, 'success-rate': 0.84, 'loss': 0.0, 'eps': 1.0}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dialogue Success Rate: 97.0\n",
      "Average Cumulative Reward: 18.74450000000001\n",
      "Average Turns: 13.48\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('plato')\n",
    "\n",
    "import shutil\n",
    "from os import chdir\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import DialogueManagement.DialoguePolicy.ReinforcementLearning.run_rl_training\n",
    "from DialogueManagement.DialoguePolicy.ReinforcementLearning.pytorch_reinforce_policy import PyTorchReinforcePolicy\n",
    "from ConversationalAgent.ConversationalSingleAgent import ConversationalSingleAgent\n",
    "from DialogueManagement.DialoguePolicy.ReinforcementLearning.run_rl_training import \\\n",
    "    build_config, run_it\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(x)\n",
    "\n",
    "def clean_dir(dir):\n",
    "    if os.path.isdir(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.mkdir(dir)\n",
    "\n",
    "class PolicyAgentModified(nn.Module):\n",
    "    def __init__(self, vocab_size, num_actions, hidden_dim=64, embed_dim=32,**kwargs) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=embed_dim, out_channels=hidden_dim, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.affine2 = nn.Linear(hidden_dim, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(2, 1)\n",
    "        features = self.convnet(x)\n",
    "        features_pooled = self.pooling(features).squeeze(2)\n",
    "        return F.softmax(self.affine2(features_pooled), dim=1)\n",
    "\n",
    "    def step(self, state):\n",
    "        probs = self.calc_probs(state)\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)\n",
    "\n",
    "    def calc_probs(self, state):\n",
    "        return self.forward(state)\n",
    "\n",
    "    def log_probs(self, state: torch.Tensor, action: torch.Tensor):\n",
    "        probs = self.calc_probs(state)\n",
    "        m = Categorical(probs)\n",
    "        return m.log_prob(action)\n",
    "\n",
    "\n",
    "base_path = \".\"\n",
    "policy_path = base_path+\"/policies/agent\"\n",
    "domain_path = \"shared_data/domain\"\n",
    "\n",
    "chdir(\"%s\" % base_path)\n",
    "clean_dir(\"logs\")\n",
    "clean_dir(\"policies\")\n",
    "\n",
    "\n",
    "config = {\n",
    "        \"GENERAL\": {\n",
    "            \"print_level\": \"info\",\n",
    "            \"interaction_mode\": \"simulation\",\n",
    "            \"agents\": 1,\n",
    "            \"runs\": 5,\n",
    "            \"experience_logs\": {\n",
    "                \"save\": False,\n",
    "                \"load\": False,\n",
    "                \"path\": \"logs/train_reinforce_logs.pkl\",\n",
    "            },\n",
    "        },\n",
    "        \"DIALOGUE\": {\n",
    "            \"num_dialogues\": 1000,\n",
    "            \"initiative\": \"system\",\n",
    "            \"domain\": \"CamRest\",\n",
    "            \"ontology_path\": domain_path+\"/alex-rules.json\",\n",
    "            \"db_path\": domain_path+\"/alex-dbase.db\",\n",
    "            \"db_type\": \"sql\",\n",
    "            \"cache_sql_results\": True,\n",
    "        },\n",
    "        \"AGENT_0\": {\n",
    "            \"role\": \"system\",\n",
    "            \"USER_SIMULATOR\": {\n",
    "                \"simulator\": \"agenda\",\n",
    "                \"patience\": 5,\n",
    "                \"pop_distribution\": [1.0],\n",
    "                \"slot_confuse_prob\": 0.0,\n",
    "                \"op_confuse_prob\": 0.0,\n",
    "                \"value_confuse_prob\": 0.0,\n",
    "            },\n",
    "            \"DM\": {\n",
    "                \"policy\": {\n",
    "                    \"type\": \"pytorch_reinforce\",\n",
    "                    \"train\": True,\n",
    "                    \"learning_rate\": 0.01,\n",
    "                    \"learning_decay_rate\": 0.995,\n",
    "                    \"discount_factor\": 0.99,\n",
    "                    \"exploration_rate\": 1.0,\n",
    "                    \"exploration_decay_rate\": 1.0,\n",
    "                    \"min_exploration_rate\": 0.01,\n",
    "                    \"policy_path\": policy_path,\n",
    "                    #\"PolicyAgentModelClass\":PolicyAgentModified\n",
    "                }\n",
    "            },\n",
    "            \"NLU\": None,\n",
    "            \"DST\": {\"dst\": \"dummy\"},\n",
    "            \"NLG\": None,\n",
    "        },\n",
    "    }\n",
    "\n",
    "#ca = ConversationalSingleAgent(config)\n",
    "#ca.initialize()\n",
    "#print(ca.minibatch_length)\n",
    "#print(ca.dialogue_manager.it_works)\n",
    "#ca.dialogue_manager.policy.PolicyAgentModelClass\n",
    "\n",
    "run_it(config, 100)\n",
    "config['AGENT_0']['DM']['policy']['train']=False\n",
    "run_it(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plato)",
   "language": "python",
   "name": "plato"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
